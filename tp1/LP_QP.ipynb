{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"Fig/Ensimag.png\" width=\"30%\" height=\"30%\"></center>\n",
    "<center><h3>ENSIMAG  -- 2A</h3></center>\n",
    "<hr>\n",
    "<center><h1>Optimisation Num√©rique</h1></center>\n",
    "<center><h2>TP : Linear and Quadratic programs (1.5h)</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structure of an optimization program\n",
    "\n",
    "An optimization program can be practically divided into three parts:\n",
    "* the *run* environment, in which you test, run your program, and display results.\n",
    "* the *problem* part, which contains the function oracles, problem constraints, etc.\n",
    "* the *algorithmic* part, where the algorithms are coded.\n",
    "\n",
    "The main interest of such division is that these parts are interchangeable, meaning that, for instance, the algorithms of the third part can be used of a variety of problems. That is why such a decomposition is widely used.\n",
    "\n",
    "In the present lab, you will use this division:\n",
    "* `LP_and_QP_problems.ipynb` will be the *run* environment\n",
    "* `toy_problem.ipynb` will be the considered the *problem* for this lab\n",
    "* the library `cvxopt` will be used for solving all optimization problems\n",
    "\n",
    "---\n",
    "\n",
    "The following script will allow you to import *notebooks* as if you imported *python files* and will have to be executed at each time you launch Jupyter notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import start\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Regression model\n",
    "\n",
    "\n",
    "We consider the regression model\n",
    "\n",
    "$$ y=X\\theta+\\xi,\\;\\;\\xi\\sim \\mathcal{N}(0, \\sigma I_m), $$\n",
    "\n",
    "where $X\\in \\mathbb{R}^{m\\times n}$ and $y\\in \\mathbb{R}^m$ are the observed values and $\\theta\\in \\mathbb{R}^n$ is the unknown parameter we want to find. \n",
    "\n",
    "We want to find a value $\\widehat{\\theta}$ such that \n",
    "- the quadratic error $e(\\widehat{\\theta}) = 1/2 \\|X\\widehat{\\theta} - y \\|_2^2$ is (near)-minimal, that is $ \\| \\nabla e(\\widehat{\\theta}) \\| = \\| X^\\mathrm{T} (X\\widehat{\\theta} - y) \\| $ is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# the Dantzig Selector\n",
    "\n",
    "\n",
    "The **Dantzig Selector** for $\\theta$, introduced in *Emmanuel Candes and Terrence Tao \"The Dantzig selector: Statistical estimation when $p$ is much larger than $n$\". The Annals of Statistics, 2007* can be used to estimate $\\theta$ in the case of an overparametrized problem, i.e. when the dimension $n$ of $\\theta$ is well greater than the dimension of the observation $y$. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "In that case, the estimator $\\widehat{\\theta}_{DS}$ is the solution of the optimization problem \n",
    "$$\n",
    "\\widehat{\\theta}_{DS} \\in \\arg\\min_{\\theta\\in \\mathbb{R}^n} \\left\\{\\|\\theta\\|_1,\\;\\mbox{with}\\;\\|X^T(X\\theta-y)\\|_\\infty\\leq \\kappa\\sigma\\right\\},\n",
    "$$\n",
    "where $\\kappa>0$ is an *hyper-parameter*. \n",
    "\n",
    "\n",
    "The best theoretical value for $\\kappa$ is $\\nu q_{\\mathcal{N}} \\left(1-\\frac{\\alpha}{2n}\\right)$, where  $\\alpha\\in(0,1)$ is the chosen risk level (e.g. $\\alpha=.05$), $q_\\mathcal{N}(p)$ is the $p$-quantile of the standard normal distribution, and $\\nu=\\max_j\\|[X]_j\\|_2$ is the maximal column norm of matrix $X$.\n",
    "\n",
    "\n",
    "**Objective:** Implement a function that return the Dantzig estimator $\\widehat{\\theta}_{DS}$ from input $(y,X,\\sigma)$ using linear programming solver `cvxopt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reformulate the $\\arg\\min$ problem as a linear program.\n",
    "\n",
    "\n",
    "> Write a function `DantzigSelector` that takes `y,X,sigma` as an input and outputs $\\widehat{\\theta}_{DS}$ by using the linear program solver of the library `cvxopt` <a href=\"http://cvxopt.org/userguide/coneprog.html#linear-programming\">lp</a> which, given $c, G, h$ solves the problem\n",
    "$$ \\min_x c^\\mathrm{T}x ~~~~~~ \\text{ subject to } Gx \\leq h $$\n",
    "where the inequality is elementwise.\n",
    "\n",
    "*Hint: Useful functions are* `np.concatenate` `np.zeros` `np.eye` `np.hstack` `np.vstack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def DantzigSelector(y, X, sigma):\n",
    "    \"\"\"\n",
    "    Compute the Dantzig Selector estimator.\n",
    "    \n",
    "    Parameters:\n",
    "    y (numpy.ndarray): Observation vector.\n",
    "    X (numpy.ndarray): Design matrix.\n",
    "    sigma (float): Noise level.\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The Dantzig Selector estimator.\n",
    "    \"\"\"\n",
    "    \n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # Compute the hyper-parameter kappa\n",
    "    alpha = 0.05\n",
    "    nu = max(np.linalg.norm(X, axis=0))\n",
    "    kappa = nu*norm.ppf(1-alpha/(2.0*n))\n",
    "    \n",
    "    # Define the linear program components\n",
    "    c = np.concatenate([np.ones(n), np.zeros(n)])\n",
    "    G = np.vstack([\n",
    "        np.hstack([X.T @ X, -X.T @ X]),\n",
    "        np.hstack([-X.T @ X, X.T @ X]),\n",
    "        np.hstack([-np.eye(n), np.zeros((n, n))]),\n",
    "        np.hstack([np.zeros((n, n)), -np.eye(n)])\n",
    "    ])\n",
    "    h = np.concatenate([\n",
    "        X.T @ y + kappa * sigma * np.ones(n),\n",
    "        -X.T @ y + kappa * sigma * np.ones(n),\n",
    "        np.zeros(n),\n",
    "        np.zeros(n)\n",
    "    ])\n",
    "    \n",
    "    # Convert to cvxopt matrices\n",
    "    c = matrix(c)\n",
    "    G = matrix(G)\n",
    "    h = matrix(h)\n",
    "    \n",
    "    # Solve the linear program\n",
    "    sol = solvers.lp(c, G, h)\n",
    "    \n",
    "    # Extract the solution\n",
    "    theta_ds = np.array(sol['x'][:n])\n",
    "    \n",
    "    return theta_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Test your code on the toy problem given in `toy_problem.ipynb`. For this randomly generated problem, there is a true $\\theta$ upon which the problem is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from toy_problem.ipynb\n",
      "importing notebook from toy_problem.ipynb\n",
      "     pcost       dcost       gap    pres   dres   k/t\n",
      " 0: -2.8517e-01 -3.0477e+02  2e+03  3e+00  2e+00  1e+00\n",
      " 1:  1.1094e+00 -4.4400e+01  2e+02  5e-01  3e-01  2e+00\n",
      " 2: -8.0544e-01 -6.5734e+00  2e+01  7e-02  4e-02  3e-01\n",
      " 3: -1.0945e-02 -8.1539e-02  2e-01  8e-04  5e-04  5e-03\n",
      " 4: -1.0940e-04 -8.1499e-04  2e-03  8e-06  5e-06  5e-05\n",
      " 5: -1.0940e-06 -8.1499e-06  2e-05  8e-08  5e-08  5e-07\n",
      " 6: -1.0940e-08 -8.1499e-08  2e-07  8e-10  5e-10  5e-09\n",
      " 7: -1.0940e-10 -8.1499e-10  2e-09  8e-12  5e-12  5e-11\n",
      "Optimal solution found.\n"
     ]
    }
   ],
   "source": [
    "import toy_problem as tPb\n",
    "reload(tPb)\n",
    "\n",
    "\n",
    "theta_ds = DantzigSelector(tPb.y,tPb.X,tPb.sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigate the differences between the Dantzig selector and the Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tPb.theta,'ro',label='ground truth')\n",
    "plt.plot(theta_ds,'b*',label='Dantzig selector')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# the Lasso\n",
    "\n",
    "Under the same regression model, the Least Absolute Shrinkage and Selection Operator or **lasso** for $\\theta$, introduced in *Robert Tibshirani \"Regression shrinkage and selection via the lasso\", Journal of the Royal Statistical Society, 1996* can also be used to estimate $\\theta$. \n",
    "\n",
    "The estimator $\\widehat{\\theta}_{L}$ is the solution of the optimization problem \n",
    "$$\n",
    "\\widehat{\\theta}_{L} \\in \\arg\\min_{\\theta\\in \\mathbb{R}^n} \\left\\{ \\|X\\theta - y\\|_2^2 + \\kappa \\sigma \\|\\theta\\|_1 \\right\\},\n",
    "$$\n",
    "where $\\kappa>0$ is an *hyper-parameter*. \n",
    "\n",
    "\n",
    "The best theoretical value for $\\kappa$ is the same as for the Dantzig selector: $\\nu q_{\\mathcal{N}} \\left(1-\\frac{\\alpha}{2n}\\right)$, where  $\\alpha\\in(0,1)$ is the chosen risk level (e.g. $\\alpha=.05$), $q_\\mathcal{N}(p)$ is the $p$-quantile of the standard normal distribution, and $\\nu=\\max_j\\|[X]_j\\|_2$ is the maximal column norm of matrix $X$.\n",
    "\n",
    "\n",
    "**Objective:** Implement a function that return the lasso estimator $\\widehat{\\theta}_{L}$ from input $(y,X,\\sigma)$ using quadratic programming solver `cvxopt`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Reformulate the $\\arg\\min$ problem as a quadratic program.\n",
    "\n",
    "\n",
    "> Write a function `Lasso` that takes `y,X,sigma` as an input and outputs $\\widehat{\\theta}_{L}$ by using the quadratic program solver of the library `cvxopt` <a href=\"http://cvxopt.org/userguide/coneprog.html#quadratic-programming\">qp</a> which, given $P,q, G, h$ solves the problem\n",
    "$$ \\min_x 1/2 x^\\mathrm{T} P x + q^\\mathrm{T}x ~~~~~~ \\text{ subject to } Gx \\leq h $$\n",
    "where the inequality is elementwise.\n",
    "\n",
    "*Hint: Useful functions are* `np.concatenate` `np.zeros` `np.eye` `np.hstack` `np.vstack`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def Lasso(y,X,sigma):\n",
    "    \n",
    "    # Extracting the sizes\n",
    "    m,n = X.shape\n",
    "    \n",
    "    # Computing kappa\n",
    "    alpha = 0.05\n",
    "    nu = max(np.linalg.norm(X, axis=0))\n",
    "    kappa = nu*norm.ppf(1-alpha/(2.0*n))\n",
    "    \n",
    "    #####################################################\n",
    "    # COMPUTE AND SOLVE QP PROBLEM\n",
    "    #####################################################\n",
    "    # Prepare P, q, G, h\n",
    "    P = np.block([[np.eye(n), np.zeros((n,m))], [np.zeros((m,n)), np.zeros((m,m))]])\n",
    "    q = np.block([np.zeros(n), kappa*np.ones(m)])\n",
    "    G = np.block([[X.T, -np.eye(m)], [-X.T, -np.eye(m)]])\n",
    "    h = np.block([y, -y])\n",
    "    \n",
    "    \n",
    "    P_cvx = matrix(P)\n",
    "    q_cvx = matrix(q)\n",
    "    G_cvx = matrix(G)\n",
    "    h_cvx = matrix(h)\n",
    "    \n",
    "    sol = solvers.qp(P_cvx, q_cvx, G_cvx, h_cvx)\n",
    "    x_cvx = sol['x']\n",
    "    # x = np.squeeze(np.array(x_cvx))\n",
    "    x = np.array(x_cvx).flatten()\n",
    "    \n",
    "    # Extract theta    \n",
    "    theta = x[:n]\n",
    "\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Test your code on the toy problem given in `toy_problem.ipynb`. For this randomly generated problem, there is a true $\\theta$ upon which the problem is built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from toy_problem.ipynb\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 256 and the array at index 1 has size 72",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtoy_problem\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtPb\u001b[39;00m\n\u001b[1;32m      2\u001b[0m reload(tPb)\n\u001b[0;32m----> 5\u001b[0m theta_l \u001b[38;5;241m=\u001b[39m \u001b[43mLasso\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtPb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtPb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtPb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m, in \u001b[0;36mLasso\u001b[0;34m(y, X, sigma)\u001b[0m\n\u001b[1;32m     20\u001b[0m P \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mblock([[np\u001b[38;5;241m.\u001b[39meye(n), np\u001b[38;5;241m.\u001b[39mzeros((n,m))], [np\u001b[38;5;241m.\u001b[39mzeros((m,n)), np\u001b[38;5;241m.\u001b[39mzeros((m,m))]])\n\u001b[1;32m     21\u001b[0m q \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mblock([np\u001b[38;5;241m.\u001b[39mzeros(n), kappa\u001b[38;5;241m*\u001b[39mnp\u001b[38;5;241m.\u001b[39mones(m)])\n\u001b[0;32m---> 22\u001b[0m G \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meye\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mblock([y, \u001b[38;5;241m-\u001b[39my])\n\u001b[1;32m     26\u001b[0m P_cvx \u001b[38;5;241m=\u001b[39m matrix(P)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:872\u001b[0m, in \u001b[0;36mblock\u001b[0;34m(arrays)\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _block_slicing(arrays, list_ndim, result_ndim)\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_block_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_ndim\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:916\u001b[0m, in \u001b[0;36m_block_concatenate\u001b[0;34m(arrays, list_ndim, result_ndim)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_block_concatenate\u001b[39m(arrays, list_ndim, result_ndim):\n\u001b[0;32m--> 916\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_ndim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m list_ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;66;03m# Catch an edge case where _block returns a view because\u001b[39;00m\n\u001b[1;32m    919\u001b[0m         \u001b[38;5;66;03m# `arrays` is a single numpy array and not a list of numpy arrays.\u001b[39;00m\n\u001b[1;32m    920\u001b[0m         \u001b[38;5;66;03m# This might copy scalars or lists twice, but this isn't a likely\u001b[39;00m\n\u001b[1;32m    921\u001b[0m         \u001b[38;5;66;03m# usecase for those interested in performance\u001b[39;00m\n\u001b[1;32m    922\u001b[0m         result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:683\u001b[0m, in \u001b[0;36m_block\u001b[0;34m(arrays, max_depth, result_ndim, depth)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03mInternal implementation of block based on repeated concatenation.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03m`arrays` is the argument passed to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03mfor details).\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m max_depth:\n\u001b[0;32m--> 683\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [_block(arr, max_depth, result_ndim, depth\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    684\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _concatenate(arrs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m(max_depth\u001b[38;5;241m-\u001b[39mdepth))\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# We've 'bottomed out' - arrays is either a scalar or an array\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# type(arrays) is not list\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:683\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;124;03mInternal implementation of block based on repeated concatenation.\u001b[39;00m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;124;03m`arrays` is the argument passed to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[38;5;124;03mfor details).\u001b[39;00m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m max_depth:\n\u001b[0;32m--> 683\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [\u001b[43m_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult_ndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    684\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m    685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _concatenate(arrs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m(max_depth\u001b[38;5;241m-\u001b[39mdepth))\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# We've 'bottomed out' - arrays is either a scalar or an array\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# type(arrays) is not list\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/numpy/core/shape_base.py:685\u001b[0m, in \u001b[0;36m_block\u001b[0;34m(arrays, max_depth, result_ndim, depth)\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m depth \u001b[38;5;241m<\u001b[39m max_depth:\n\u001b[1;32m    683\u001b[0m     arrs \u001b[38;5;241m=\u001b[39m [_block(arr, max_depth, result_ndim, depth\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    684\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 685\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_concatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmax_depth\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mdepth\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;66;03m# We've 'bottomed out' - arrays is either a scalar or an array\u001b[39;00m\n\u001b[1;32m    688\u001b[0m     \u001b[38;5;66;03m# type(arrays) is not list\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _atleast_nd(arrays, result_ndim)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 256 and the array at index 1 has size 72"
     ]
    }
   ],
   "source": [
    "import toy_problem as tPb\n",
    "reload(tPb)\n",
    "\n",
    "\n",
    "theta_l = Lasso(tPb.y,tPb.X,tPb.sigma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Investigate the differences between the Lasso and the Ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tPb.theta,'ro',label='ground truth')\n",
    "plt.plot(theta_l,'k*',label='Lasso')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing and Improving\n",
    "\n",
    "\n",
    "> Compute the lasso and Dantzig selector solutions for the same problem and investigate their compared performance graphically and by computing the error on the null and non-null coordinates of theta.\n",
    "\n",
    "\n",
    "> Play with the values of $n,m,\\sigma, S$ to exhibit differences in behaviors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toy_problem as tPb\n",
    "reload(tPb)\n",
    "\n",
    "\n",
    "theta_l = Lasso(tPb.y,tPb.X,tPb.sigma)\n",
    "theta_ds = DantzigSelector(tPb.y,tPb.X,tPb.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tPb.theta,'ro',label='ground truth')\n",
    "plt.plot(theta_ds,'b*',label='Dantzig selector')\n",
    "plt.plot(theta_l,'k*',label='Lasso')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tPb.theta[tPb.non_null],'ro',label='ground truth')\n",
    "plt.plot(theta_ds[tPb.non_null],'b*',label='Dantzig selector')\n",
    "plt.plot(theta_l[tPb.non_null],'k*',label='Lasso')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "err_theta_DS = np.linalg.norm(theta_ds[tPb.non_null] -tPb.theta[tPb.non_null]  , ord=1)\n",
    "err_theta_L = np.linalg.norm(theta_l[tPb.non_null]-tPb.theta[tPb.non_null] , ord=1)\n",
    "\n",
    "print(\"Error on the non-null coefficients\\n Dantzig selec. \\t Lasso\")\n",
    "print(err_theta_DS,err_theta_L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_supp_DS = 0\n",
    "err_supp_L = 0\n",
    "for i in range(tPb.n):\n",
    "    if i not in  tPb.non_null:\n",
    "        err_supp_DS += np.abs(theta_ds[i])\n",
    "        err_supp_L += np.abs(theta_l[i])\n",
    "\n",
    "print(\"Error on the null coefficients\\n Dantzig selec. \\t Lasso\")\n",
    "print(float(err_supp_DS),float(err_supp_L))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Error on y \\n Dantzig selec. \\t Lasso\")\n",
    "print(float(np.linalg.norm(np.dot(tPb.X, theta_ds ) - tPb.y )),float(np.linalg.norm(np.dot(tPb.X, theta_l ) - tPb.y )))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Quadratic error \\n Dantzig selec. \\t Lasso\")\n",
    "print(float(np.linalg.norm(np.dot(tPb.X.T , np.dot(tPb.X, theta_ds ) - tPb.y ))),float(np.linalg.norm(np.dot(tPb.X.T , np.dot(tPb.X, theta_l ) - tPb.y )))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To go further\n",
    "\n",
    "\n",
    "### Improved Estimators\n",
    "\n",
    "A popular improvement of these estimators is to weigh the threshold $\\kappa$ with the norm corresponding column of $X$.\n",
    "\n",
    "The improved Dantzig and Lasso estimators $\\widehat{\\theta'}_{DS}$ and $\\widehat{\\theta'}_{L}$  are thus solutions of  \n",
    "$$\n",
    "\\widehat{\\theta}_{DS} \\in \\arg\\min_{\\theta\\in \\mathbb{R}^n} \\left\\{\\|\\theta\\|_1,\\;\\mbox{with}\\;| [ X^T(X\\theta-y)]_i  | \\leq \\kappa_i \\sigma ~~ \\forall i\\right\\},\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\widehat{\\theta}_{L} \\in \\arg\\min_{\\theta\\in \\mathbb{R}^n} \\left\\{ \\|X\\theta - y\\|_2^2 + \\sum_{i=1}^n \\kappa_i \\sigma |\\theta_i | \\right\\},\n",
    "$$\n",
    "where $\\kappa_i = \\| X_i \\|_2 \\kappa = \\| X_i \\|_2 q_{\\mathcal{N}} \\left(1-\\frac{\\alpha}{2n}\\right) $ where $\\| X_i \\|_2$ is the $2$-norm of the $i$-th column of $X$.\n",
    "\n",
    "\n",
    "\n",
    "> Investigate the pertinence of this improvement. (Get rid of the normalization in the problem). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def DantzigSelectorImproved(y,X,sigma):\n",
    "    \n",
    "    # Extracting the sizes\n",
    "    m,n = X.shape\n",
    "    \n",
    "    # Computing kappa\n",
    "    alpha = 0.05\n",
    "    #### WARNING: Error in the question !\n",
    "    nu = 1 #max(np.linalg.norm(X, axis=0))\n",
    "    kappa = nu*norm.ppf(1-alpha/(2.0*n))\n",
    "    \n",
    "    # Kappa vector\n",
    "    kappa_vec = np.linalg.norm(X, ord=2, axis=0) * kappa\n",
    "    assert kappa_vec.shape == (n,)\n",
    "    \n",
    "    #####################################################\n",
    "    # COMPUTE AND SOLVE LP PROBLEM\n",
    "    #####################################################\n",
    "    # Prepare c, G, h\n",
    "    c_cvx = matrix(c)\n",
    "    G_cvx = matrix(G)\n",
    "    h_cvx = matrix(h)\n",
    "    \n",
    "    sol = solvers.conelp(c_cvx, G_cvx, h_cvx)\n",
    "    x_cvx = sol['x']\n",
    "    x = np.squeeze(np.array(x_cvx))\n",
    "    assert x.shape == (2*n,)\n",
    "    \n",
    "    theta = ... # x[:n]\n",
    "    assert theta.shape == (n,)\n",
    "    \n",
    "    return  theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cvxopt import matrix, solvers\n",
    "\n",
    "from scipy.stats import norm\n",
    "import numpy as np\n",
    "\n",
    "def LassoImproved(y,X,sigma):\n",
    "    \n",
    "    # Extracting the sizes\n",
    "    m,n = X.shape\n",
    "    \n",
    "    # Computing kappa\n",
    "    alpha = 0.05\n",
    "    nu = 1 # max(np.linalg.norm(X, axis=0))\n",
    "    kappa = nu*norm.ppf(1-alpha/(2.0*n))\n",
    "    \n",
    "    # Kappa vector\n",
    "    kappa_vec = np.linalg.norm(X, ord=2, axis=0) * kappa\n",
    "    assert kappa_vec.shape == (n,)\n",
    "    \n",
    "    #####################################################\n",
    "    # COMPUTE AND SOLVE QP PROBLEM\n",
    "    #####################################################\n",
    "    # Prepare P, q, G, h\n",
    "    P_cvx = matrix(P)\n",
    "    q_cvx = matrix(q)\n",
    "    G_cvx = matrix(G)\n",
    "    h_cvx = matrix(h)\n",
    "    \n",
    "    sol = solvers.qp(P_cvx, q_cvx, G_cvx, h_cvx)\n",
    "    x_cvx = sol['x']\n",
    "    x = np.squeeze(np.array(x_cvx))\n",
    "    assert x.shape == (2*n,)\n",
    "    \n",
    "    theta = x[:n]\n",
    "    assert theta.shape == (n,)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toy_problem as tPb\n",
    "reload(tPb)\n",
    "\n",
    "theta_l = Lasso(tPb.y,tPb.X,tPb.sigma)\n",
    "theta_ds = DantzigSelector(tPb.y,tPb.X,tPb.sigma)\n",
    "theta_li = LassoImproved(tPb.y,tPb.X,tPb.sigma)\n",
    "theta_dsi = DantzigSelectorImproved(tPb.y,tPb.X,tPb.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(tPb.theta,'ro',label='ground truth')\n",
    "plt.plot(theta_ds,'b*',label='Dantzig selector')\n",
    "plt.plot(theta_l,'k*',label='Lasso')\n",
    "plt.plot(theta_dsi,'g*',label='Improved Dantzig selector')\n",
    "plt.plot(theta_li,'y*',label='Improved Lasso')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_theta_DS = np.linalg.norm(theta_ds[tPb.non_null] -tPb.theta[tPb.non_null]  , ord=1)\n",
    "err_theta_L = np.linalg.norm(theta_l[tPb.non_null]-tPb.theta[tPb.non_null] , ord=1)\n",
    "err_theta_DSI = np.linalg.norm(theta_dsi[tPb.non_null] -tPb.theta[tPb.non_null]  , ord=1)\n",
    "err_theta_LI = np.linalg.norm(theta_li[tPb.non_null]-tPb.theta[tPb.non_null] , ord=1)\n",
    "\n",
    "print(\"Error on the non-null coefficients\")\n",
    "print(err_theta_DS,err_theta_L, err_theta_DSI, err_theta_LI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crossed Validation of the thresholds\n",
    "\n",
    "The values of $\\kappa$ is heavily linked to the noise standard deviation $\\sigma$ and theoretical considerations about $X$ and $\\theta$. A practical way to choose $\\kappa$ without the knowledge of $\\sigma$ is to use *cross-validation*.\n",
    "\n",
    "- Split y and X in two parts column-wise, one part for *training* and one for *testing*.\n",
    "- For several values of $\\kappa$, solve the estimation problem *on the training part* using $\\kappa$ to get a estimate $\\widehat{\\theta}_\\kappa$.\n",
    "- For each $\\widehat{\\theta}_\\kappa$, compute the error *on the testing part* $e(\\kappa) = \\| y_{test}-X_{test}\\widehat{\\theta}_\\kappa \\|$.  \n",
    "- Choose the value that minimize this error $\\widehat{\\kappa} = \\arg \\min_{\\kappa} e(\\kappa)$.\n",
    "\n",
    "\n",
    "> Implement a cross validation procedure to choose $\\kappa$. Compare the value and the outputted estimate with the theoretic value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
